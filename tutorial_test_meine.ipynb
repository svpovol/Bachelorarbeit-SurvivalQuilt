{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#user defined\n",
    "from class_SurvivalQuilts import SurvivalQuilts\n",
    "from utils_eval import calc_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT DATASET\n",
    "    In this tutorial, preprocessed METABRIC dataset is used as a toy example.\n",
    "    Please see the data type to use Survival Quilts on your own datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================================================================#\n",
    "##### USER-DEFINED FUNCTIONS\n",
    "def f_get_Normalization(X, norm_mode):\n",
    "    num_Patient, num_Feature = np.shape(X)\n",
    "\n",
    "    if norm_mode == 'standard': #zero mean unit variance\n",
    "        for j in range(num_Feature):\n",
    "            if np.std(X[:,j]) != 0:\n",
    "                X[:,j] = (X[:,j] - np.mean(X[:, j]))/np.std(X[:,j])\n",
    "            else:\n",
    "                X[:,j] = (X[:,j] - np.mean(X[:, j]))\n",
    "    elif norm_mode == 'normal': #min-max normalization\n",
    "        for j in range(num_Feature):\n",
    "            X[:,j] = (X[:,j] - np.min(X[:,j]))/(np.max(X[:,j]) - np.min(X[:,j]))\n",
    "    else:\n",
    "        print(\"INPUT MODE ERROR!\")\n",
    "\n",
    "    return X\n",
    "#=================================================================#\n",
    "SEED=4321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit normalisation: funktioniert nur ohne CoxPH!!\n",
    "file='/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/hu_gitHub/ndb10.csv'\n",
    "df = pd.read_csv(file, sep=',')\n",
    "\n",
    "cols = ['int.rate', 'orig.upb', 'fico.score', 'dti.r',\n",
    "       'ltv.r', 'bal.repaid', 't.act.12m', 't.del.30d.12m', 't.del.60d.12m',\n",
    "       'hpi.st.d.t.o', 'hpi.zip.o', 'hpi.zip.d.t.o', 'ppi.c.FRMA',\n",
    "       'TB10Y.d.t.o', 'FRMA30Y.d.t.o', 'ppi.o.FRMA', 'equity.est',\n",
    "       'hpi.st.log12m', 'hpi.r.st.us', 'hpi.r.zip.st', 'st.unemp.r12m',\n",
    "       'st.unemp.r3m', 'TB10Y.r12m', 'T10Y3MM', 'T10Y3MM.r12m']\n",
    "    \n",
    "label           = np.asarray(df[['default']])\n",
    "time            = np.asarray(df[['time']])\n",
    "df = df.drop(['label', 'payoff', 'current_year','default','time'], axis=1)\n",
    "data            = np.asarray(df[cols])\n",
    "data            = f_get_Normalization(data, 'standard')\n",
    "\n",
    "X = pd.DataFrame(data,columns= cols)\n",
    "T=  pd.DataFrame(time,columns =[['time']])\n",
    "Y=  pd.DataFrame(label,columns =[['label']])\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 23, 36]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/hu_gitHub/ndb5.csv'\n",
    "df = pd.read_csv(file, sep=',')\n",
    "Y           = df[['default']]\n",
    "T            = df[['time']]\n",
    "df = df.drop(['label', 'payoff', 'current_year','default','time'], axis=1)\n",
    "X = df\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "\n",
    "eval_time_horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time    2160\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(T*30).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time\n",
       "0        7\n",
       "1       20\n",
       "2       25\n",
       "3       20\n",
       "4        3\n",
       "...    ...\n",
       "9995    11\n",
       "9996    15\n",
       "9997     9\n",
       "9998    44\n",
       "9999    12\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = early repayment\n",
    "SEED=4321\n",
    "file='/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/meine/newdata_ER.csv'\n",
    "df = pd.read_csv(file, sep=',')\n",
    "Y  = df[['label']]\n",
    "T  = df[['time']]\n",
    "df = df.drop(['label', 'current_year','time'], axis=1)\n",
    "X  = df\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = early repayment NORMALIZATION\n",
    "file='/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/meine/newdata_ER.csv'\n",
    "df = pd.read_csv(file, sep=',')\n",
    "label           = np.asarray(df[['label']])\n",
    "time            = np.asarray(df[['time']])\n",
    "df = df.drop(['label', 'current_year','time'], axis=1)\n",
    "cols = df.columns\n",
    "data            = np.asarray(df[cols])\n",
    "data            = f_get_Normalization(data, 'standard')\n",
    "\n",
    "X = pd.DataFrame(data,columns= cols)\n",
    "T=  pd.DataFrame(time,columns =[['time']])\n",
    "Y=  pd.DataFrame(label,columns =[['label']])\n",
    "\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mortage NORMALIZATION\n",
    "file = '/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/hu_gitHub/WideFormatMortgageAfterRemovingNull.csv'\n",
    "df = pd.read_csv(file, sep=',')\n",
    "\n",
    "label           = np.asarray(df[['default_time']])\n",
    "time            = np.asarray(df[['duration']])\n",
    "df = df.drop([\"id\", \"first_time\", \"payoff_time\", \"status_time\", \"time\",'duration','default_time'], axis=1)\n",
    "cols=df.columns\n",
    "data            = np.asarray(df[cols])\n",
    "data            = f_get_Normalization(data, 'standard')\n",
    "\n",
    "X = pd.DataFrame(data,columns= cols).iloc[:5000,]\n",
    "T=  pd.DataFrame(time,columns =[['time']]).iloc[:5000,]\n",
    "Y=  pd.DataFrame(label,columns =[['label']]).iloc[:5000,]\n",
    "\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mortage\n",
    "file = '/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/hu_gitHub/WideFormatMortgageAfterRemovingNull.csv'\n",
    "df = pd.read_csv(file, sep=',')\n",
    "\n",
    "Y           = df[['default_time']].iloc[:5000,]\n",
    "T            = df[['duration']].iloc[:5000,]\n",
    "df = df.drop([\"id\", \"first_time\", \"payoff_time\", \"status_time\", \"time\",'duration','default_time'], axis=1)\n",
    "X           = df.iloc[:5000,]\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   orig_time                5000 non-null   int64  \n",
      " 1   mat_time                 5000 non-null   int64  \n",
      " 2   balance_time             5000 non-null   float64\n",
      " 3   LTV_time                 5000 non-null   float64\n",
      " 4   interest_rate_time       5000 non-null   float64\n",
      " 5   hpi_time                 5000 non-null   float64\n",
      " 6   gdp_time                 5000 non-null   float64\n",
      " 7   uer_time                 5000 non-null   float64\n",
      " 8   REtype_CO_orig_time      5000 non-null   int64  \n",
      " 9   REtype_PU_orig_time      5000 non-null   int64  \n",
      " 10  REtype_SF_orig_time      5000 non-null   int64  \n",
      " 11  investor_orig_time       5000 non-null   int64  \n",
      " 12  balance_orig_time        5000 non-null   float64\n",
      " 13  FICO_orig_time           5000 non-null   int64  \n",
      " 14  LTV_orig_time            5000 non-null   float64\n",
      " 15  Interest_Rate_orig_time  5000 non-null   float64\n",
      " 16  hpi_orig_time            5000 non-null   float64\n",
      "dtypes: float64(10), int64(7)\n",
      "memory usage: 664.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(       default_time\n",
       " count        1804.0\n",
       " mean            1.0\n",
       " std             0.0\n",
       " min             1.0\n",
       " 25%             1.0\n",
       " 50%             1.0\n",
       " 75%             1.0\n",
       " max             1.0,\n",
       "        default_time\n",
       " count        3196.0\n",
       " mean            0.0\n",
       " std             0.0\n",
       " min             0.0\n",
       " 25%             0.0\n",
       " 50%             0.0\n",
       " 75%             0.0\n",
       " max             0.0,\n",
       "        default_time\n",
       " count   5000.000000\n",
       " mean       0.360800\n",
       " std        0.480281\n",
       " min        0.000000\n",
       " 25%        0.000000\n",
       " 50%        0.000000\n",
       " 75%        1.000000\n",
       " max        1.000000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.info()\n",
    "Y[Y==1].describe(),Y[Y==0].describe(),Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/hu_gitHub/ndb10.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN SURVIVAL QUILTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial training of underlying models...\n",
      "CV.. 1/5\n",
      "CV.. 2/5\n",
      "CV.. 3/5\n",
      "CV.. 4/5\n",
      "CV.. 5/5\n",
      "TIME K = 0\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]]\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]]\n",
      "[[-0.65285632]]\n",
      "=========== BO Finished ===========\n",
      "!X_step_ens aus dem W gewählt wird:  [[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.01428985 0.14846811 0.15378349 0.23555761 0.23580347 0.21209747]\n",
      " [0.17938163 0.16766643 0.13544851 0.18059268 0.17070634 0.16620442]\n",
      " [0.00946936 0.21334632 0.2081924  0.22186073 0.18981076 0.15732043]\n",
      " [0.2081137  0.23704934 0.01186351 0.23589829 0.07538698 0.23168817]\n",
      " [0.18840437 0.08726027 0.18290678 0.20850972 0.15431311 0.17860576]\n",
      " [0.15646927 0.18982747 0.19087958 0.19364245 0.17393942 0.09524181]\n",
      " [0.16401792 0.17533367 0.1669705  0.17707723 0.18333534 0.13326534]\n",
      " [0.22091684 0.11980729 0.30540088 0.19187975 0.05452435 0.10747088]\n",
      " [0.19557414 0.10889397 0.17631396 0.17068646 0.15381741 0.19471406]]\n",
      "!Y_step_ens aus dem W idx gewählt wird:  [[-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]\n",
      " [-0.65285632]]\n",
      "out_itr: 0 | BEST X: [[0.99999999 0.         0.         0.         0.         0.        ]] for K=  1 for num_outer=  1\n",
      "-0.6666666666666666 tmp_c[0] = metric_BRIER_.mean() =  0.4463509229889082 beta_ = c =  0.3288335103924418\n",
      "out_itr: 0 | Lambda: 0.8927018459778164 | Rho: 0.25\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  -0.6666666666666666 -0.6666666666666666\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  0.4463509229889082 0.4463509229889082\n",
      "TIME K = 1\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.99999999 0.         0.         0.         0.         0.        ]]\n",
      "[[0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[-0.60289014]]\n",
      "=========== BO Finished ===========\n",
      "!X_step_ens aus dem W gewählt wird:  [[0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.1948015  0.20331124 0.20469351 0.19985183 0.14817719 0.04916473]\n",
      " [0.15310504 0.18428438 0.17918072 0.16560188 0.13914689 0.17868109]\n",
      " [0.05352672 0.25716233 0.23536534 0.23409164 0.12692842 0.09292555]\n",
      " [0.15574443 0.08776004 0.10063788 0.26465404 0.23302173 0.15818188]\n",
      " [0.17405998 0.12994041 0.21168276 0.0533159  0.16776998 0.26323097]\n",
      " [0.28680928 0.08044273 0.20159706 0.15412454 0.03548417 0.24154221]\n",
      " [0.21901652 0.05600648 0.28468344 0.14330066 0.18561086 0.11138204]\n",
      " [0.16994489 0.17813701 0.12246636 0.18212053 0.15619888 0.19113233]\n",
      " [0.17671863 0.17863026 0.18161127 0.10806905 0.16520329 0.18976751]]\n",
      "!Y_step_ens aus dem W idx gewählt wird:  [[-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]\n",
      " [-0.60289014]]\n",
      "out_itr: 0 | BEST X: [[0.         0.         0.         0.         0.         0.99999999]] for K=  2 for num_outer=  1\n",
      "-0.6666666666666666 tmp_c[0] = metric_BRIER_.mean() =  0.8821853236085031 beta_ = c =  0.6296451834766201\n",
      "out_itr: 0 | Lambda: 1.7643706472170062 | Rho: 0.25\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  -0.6666666666666666 -0.6666666666666666\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  0.8821853236085031 0.8821853236085031\n",
      "TIME K = 2\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[-0.52895269]]\n",
      "=========== BO Finished ===========\n",
      "!X_step_ens aus dem W gewählt wird:  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99999990e-01]\n",
      " [2.51009572e-01 1.55330004e-01 2.20420914e-01 1.11176944e-01\n",
      "  2.47337781e-01 1.47247812e-02]\n",
      " [2.35397685e-01 2.37268246e-01 2.12313807e-01 7.80896341e-02\n",
      "  2.36794133e-01 1.36493575e-04]\n",
      " [1.91309826e-01 1.60445306e-01 1.46633182e-01 1.92484439e-01\n",
      "  1.56650118e-01 1.52477127e-01]\n",
      " [5.50305731e-02 2.12016018e-01 2.52737798e-01 1.69985177e-01\n",
      "  1.40348336e-01 1.69882096e-01]\n",
      " [1.60563320e-01 3.62752554e-01 2.81638706e-04 9.08124877e-02\n",
      "  3.58998782e-01 2.65912133e-02]\n",
      " [2.51989368e-02 8.41622731e-02 4.21635692e-01 2.87946052e-01\n",
      "  2.96231716e-02 1.51433869e-01]\n",
      " [2.24901733e-01 2.42561493e-01 9.04512972e-02 1.64148585e-01\n",
      "  1.97965046e-02 2.58140384e-01]\n",
      " [1.37275401e-01 1.47506400e-01 1.69536491e-01 1.72895536e-01\n",
      "  1.85050043e-01 1.87736126e-01]\n",
      " [1.78283342e-01 7.69094402e-02 2.38688613e-01 1.70718589e-01\n",
      "  1.89544290e-01 1.45855723e-01]]\n",
      "!Y_step_ens aus dem W idx gewählt wird:  [[-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]\n",
      " [-0.52895269]]\n",
      "out_itr: 0 | BEST X: [[0.         0.         0.         0.         0.         0.99999999]] for K=  3 for num_outer=  1\n",
      "-0.6666666666666666 tmp_c[0] = metric_BRIER_.mean() =  1.1497991557819733 beta_ = c =  0.7787008155262602\n",
      "out_itr: 0 | Lambda: 2.2995983115639467 | Rho: 0.25\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  -0.6666666666666666 -0.6666666666666666\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  1.1497991557819733 1.1497991557819733\n",
      "TIME K = 3\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[-0.45508487]]\n",
      "=========== BO Finished ===========\n",
      "!X_step_ens aus dem W gewählt wird:  [[0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.17338633 0.20682919 0.20849233 0.19687303 0.18853164 0.02588747]\n",
      " [0.17461047 0.17660203 0.16770048 0.18197414 0.17784484 0.12126804]\n",
      " [0.20965084 0.01412724 0.26912411 0.17188563 0.07815573 0.25705644]\n",
      " [0.19901773 0.08274247 0.32897301 0.17680143 0.07631654 0.13614882]\n",
      " [0.1817327  0.17303256 0.18269062 0.16330373 0.15976809 0.13947229]\n",
      " [0.09651381 0.18709257 0.19143014 0.19280112 0.1475446  0.18461775]\n",
      " [0.18386029 0.20371954 0.18666956 0.1145056  0.19165243 0.11959259]\n",
      " [0.18594681 0.17761554 0.16779329 0.18957124 0.09900585 0.18006727]\n",
      " [0.07085476 0.18376521 0.18974257 0.19366061 0.19991939 0.16205745]]\n",
      "!Y_step_ens aus dem W idx gewählt wird:  [[-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]\n",
      " [-0.45508487]]\n",
      "out_itr: 0 | BEST X: [[0.         0.         0.         0.         0.         0.99999999]] for K=  4 for num_outer=  1\n",
      "-0.6666666666666666 tmp_c[0] = metric_BRIER_.mean() =  1.2963819496602567 beta_ = c =  0.8364017371546313\n",
      "out_itr: 0 | Lambda: 2.5927638993205133 | Rho: 0.25\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  -0.6666666666666666 -0.6666666666666666\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  1.2963819496602567 1.2963819496602567\n",
      "TIME K = 4\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[-0.40701055]]\n",
      "=========== BO Finished ===========\n",
      "!X_step_ens aus dem W gewählt wird:  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 9.99999990e-01]\n",
      " [2.26849853e-01 2.31367162e-01 2.13993870e-01 2.36280982e-01\n",
      "  6.38281023e-02 2.76800291e-02]\n",
      " [2.18331355e-01 1.80368716e-01 1.44366690e-01 2.01351843e-01\n",
      "  2.16172507e-01 3.94088861e-02]\n",
      " [1.79911301e-01 1.17280594e-01 1.82866653e-01 1.77925839e-01\n",
      "  1.67656702e-01 1.74358909e-01]\n",
      " [3.38209928e-01 3.40565993e-03 3.36696341e-01 2.20952914e-01\n",
      "  9.99643122e-02 7.70841324e-04]\n",
      " [2.72612769e-01 2.39625985e-01 7.81548949e-02 6.45894687e-02\n",
      "  1.15855848e-01 2.29161030e-01]\n",
      " [1.79632994e-01 1.82306431e-01 1.89815867e-01 1.68406789e-01\n",
      "  1.29309459e-01 1.50528458e-01]\n",
      " [1.57871461e-01 1.95204393e-01 1.75652535e-01 1.95418412e-01\n",
      "  9.23507276e-02 1.83502470e-01]\n",
      " [9.78484896e-02 1.72225111e-01 1.86244437e-01 1.75839606e-01\n",
      "  1.85737790e-01 1.82104564e-01]\n",
      " [1.55091806e-01 1.73827048e-01 1.88110850e-01 1.09666239e-01\n",
      "  1.90526024e-01 1.82778032e-01]]\n",
      "!Y_step_ens aus dem W idx gewählt wird:  [[-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]\n",
      " [-0.40701055]]\n",
      "out_itr: 0 | BEST X: [[0.         0.         0.         0.         0.         0.99999999]] for K=  5 for num_outer=  1\n",
      "-0.6666666666666666 tmp_c[0] = metric_BRIER_.mean() =  1.3762734843477584 beta_ = c =  0.8667088481014531\n",
      "out_itr: 0 | Lambda: 2.752546968695517 | Rho: 0.25\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  -0.6666666666666666 -0.6666666666666666\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  1.3762734843477584 1.3762734843477584\n",
      "TIME K = 5\n",
      "[[0.99999999 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[0.         0.         0.         0.         0.         0.99999999]]\n",
      "[[-0.46014866]]\n",
      "=========== BO Finished ===========\n",
      "!X_step_ens aus dem W gewählt wird:  [[0.         0.         0.         0.         0.         0.99999999]\n",
      " [0.16580631 0.20070564 0.19333322 0.19353576 0.18755072 0.05906835]\n",
      " [0.20720745 0.20452546 0.19840779 0.18073505 0.17818115 0.03094311]\n",
      " [0.20778509 0.13044178 0.16928586 0.30173251 0.03331826 0.15743651]\n",
      " [0.04079889 0.2560492  0.21903537 0.06795854 0.19515469 0.22100331]\n",
      " [0.16931742 0.17751766 0.17055279 0.19176983 0.10230033 0.18854197]\n",
      " [0.03605953 0.20174319 0.19849204 0.18821297 0.17902341 0.19646885]\n",
      " [0.15419423 0.13669028 0.17479931 0.17894719 0.17437832 0.18099066]\n",
      " [0.17946831 0.19884709 0.1854645  0.02227821 0.20724805 0.20669383]\n",
      " [0.1877409  0.18342527 0.17644993 0.11666845 0.144674   0.19104144]]\n",
      "!Y_step_ens aus dem W idx gewählt wird:  [[-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]\n",
      " [-0.46014866]]\n",
      "out_itr: 0 | BEST X: [[0.         0.         0.         0.         0.         0.99999999]] for K=  6 for num_outer=  1\n",
      "-0.5833333333333334 tmp_c[0] = metric_BRIER_.mean() =  1.228871014164692 beta_ = c =  0.8778942670516189\n",
      "out_itr: 0 | Lambda: 2.457742028329384 | Rho: 0.25\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  -0.5833333333333334 -0.5833333333333334\n",
      "vergleich für update W!!tmp_o und tmp_o_prev:  1.228871014164692 1.228871014164692\n"
     ]
    }
   ],
   "source": [
    "model_sq = SurvivalQuilts(K=6,num_bo=10, num_cv=5,num_outer=1,step_ahead=1) #K=2,num_bo=5, num_cv=5,num_outer=3 :ndb9.cv\n",
    "model_sq.train(tr_X, tr_T, tr_Y) \n",
    "#best ndb9.cv: K=5,num_bo=75, num_cv=5,num_outer=1 models:\n",
    "#['CoxPH', 'CoxPHRidge', 'LogNormal', 'LogLogistic']\n",
    "\n",
    "# save model\n",
    "#import pickle \n",
    "#filename = './results/' + 'SurvivalQuilts.sav'\n",
    "#pickle.dump(model_sq, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST SURVIVAL QUILTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9952286370331166, 0.36276305273658005)\n",
      "(0.9942456538707999, 0.5969161731039037)\n",
      "(0.9892782969388593, 0.7539280878582325)\n",
      "['CoxPH', 'CoxPHRidge', 'Weibull', 'LogNormal', 'LogLogistic', 'RandomSurvForest']\n"
     ]
    }
   ],
   "source": [
    "pred = model_sq.predict(te_X, eval_time_horizons)\n",
    "\n",
    "for e_idx, eval_time in enumerate(eval_time_horizons):\n",
    "    print( calc_metrics(tr_T, tr_Y, te_T, te_Y, pred[:, e_idx], eval_time) )\n",
    "    \n",
    "print(model_sq.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999999, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99999999],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99999999],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99999999],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99999999],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.99999999]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred = model_sq.predict(te_X, eval_time_horizons)\n",
    "#self.model_names   = ['CoxPH', 'Weibull', 'LogNormal']\n",
    "#for e_idx, eval_time in enumerate(eval_time_horizons):\n",
    "#print( calc_metrics(tr_T, tr_Y, te_T, te_Y, pred[:, e_idx], eval_time) )\n",
    "model_sq.quilting_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoxPH\n",
      "(0.9953472437106707, 0.36331086999949197)\n",
      "(0.5, 0.3853559067867073)\n",
      "(0.5, 0.1571754462655214)\n",
      "\n",
      "\n",
      "CoxPHRidge\n",
      "(0.9958231476007862, 0.3626635805244224)\n",
      "(0.5, 0.3853559067867073)\n",
      "(0.5, 0.1571754462655214)\n",
      "\n",
      "\n",
      "Weibull\n",
      "(0.9923062104369722, 0.36245067731058545)\n",
      "(0.9874196282941636, 0.5967190688090201)\n",
      "(0.980555388717425, 0.7575686728721543)\n",
      "\n",
      "\n",
      "LogNormal\n",
      "(0.9912633248454059, 0.3624349745883508)\n",
      "(0.9911167309052896, 0.5960532511775498)\n",
      "(0.98755219172386, 0.7546588210085543)\n",
      "\n",
      "\n",
      "LogLogistic\n",
      "(0.9932280762225829, 0.36282875407602305)\n",
      "(0.9917407962387448, 0.5969667376502096)\n",
      "(0.9871465475219785, 0.7562406856933871)\n",
      "\n",
      "\n",
      "RandomSurvForest\n",
      "(0.9947615992001357, 0.36333412921446295)\n",
      "(0.9948587601961653, 0.5967087492429268)\n",
      "(0.990440953052584, 0.7495331909388094)\n",
      "\n",
      "\n",
      "3950.412891262829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.640433487054831"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in range(model_sq.M):\n",
    "    tmp_pred_eval = model_sq.underlying_models[m].predict(te_X, eval_time_horizons)\n",
    "    #Name des Modells:\n",
    "    a = str(model_sq.underlying_models[m])\n",
    "    b = a.split(\".\")\n",
    "    b = \" \".join(b[1:])\n",
    "    c = b.split()[0]\n",
    "    print(c) #Name des Modells\n",
    "    \n",
    "    if model_sq.quilting_patterns[0][m] > 0.5: #first time check\n",
    "        #print('For time = ',eval_time,'best weight in this model (',model_sq.quilting_patterns[e_idx][m],')\\n')\n",
    "        tmp_pred_LN=tmp_pred_eval\n",
    "        name = c\n",
    "    if (model_sq.quilting_patterns[0][m] > 0.) & (model_sq.quilting_patterns[0][m] <0.5):\n",
    "        print('->',model_sq.quilting_patterns[e_idx][m])\n",
    "\n",
    "    for e_idx, eval_time in enumerate(eval_time_horizons):\n",
    "        print( calc_metrics(tr_T, tr_Y, te_T, te_Y, tmp_pred_eval[:, e_idx], eval_time) )\n",
    "    print('\\n')\n",
    "print(np.sum(np.sqrt((pred-tmp_pred_LN)**2)))    \n",
    "mean_squared_error(pred,tmp_pred_LN)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " time:  14\n",
      "CoxPH           (0.9953472437106707, 0.36331086999949197)\n",
      "Temporal Quilting   (0.9952286370331166, 0.36276305273658005)\n",
      "\n",
      " time:  22\n",
      "CoxPH           (0.5, 0.3853559067867073)\n",
      "Temporal Quilting   (0.9942456538707999, 0.5969161731039037)\n",
      "\n",
      " time:  34\n",
      "CoxPH           (0.5, 0.1571754462655214)\n",
      "Temporal Quilting   (0.9892782969388593, 0.7539280878582325)\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(eval_time_horizons)):\n",
    "    print('\\n',\"time: \", eval_time_horizons[t])#,\" metric_CINDEX\",'\\n' )\n",
    "\n",
    "    print(name,\"         \",calc_metrics(tr_T, tr_Y, te_T, te_Y, tmp_pred_LN[:, t], eval_time_horizons[t]))\n",
    "    print(\"Temporal Quilting\",\" \",calc_metrics(tr_T, tr_Y, te_T, te_Y, pred[:, t], eval_time_horizons[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/hu_gitHub/ndb9.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.08 0.09 0.14]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.   0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.   0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.03 0.04]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.01 0.03]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.   0.04]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "1 [0.0025     0.09       0.28191666]\n",
      "time of default:  28\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "1 [0.53866666 0.86491666 0.91991666]\n",
      "time of default:  11\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.03       0.23916666 0.31666666]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.01 0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.02 0.04]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.   0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.01 0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.   0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.    0.06  0.075]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.03 0.04]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.         0.00333333 0.03333333]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0. 0. 0.]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.   0.01]\n",
      "\n",
      "Time:   [12, 21, 31]\n",
      "0 [0.   0.02 0.03]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=10\n",
    "end = idx+40\n",
    "for y, pr in zip(te_Y.iloc[idx:end,0],pred[idx:end,:]):\n",
    "    print('Time:  ', eval_time_horizons)\n",
    "    print(y,pr)#, '\\n')\n",
    "    if y==1:\n",
    "        print('time of default: ',te_T.iloc[idx,0])\n",
    "    print()\n",
    "    idx+=1\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.9927828026964547, 0.2641950444596503)\n",
    "(0.9592583449503984, 0.5217450168586214)\n",
    "(0.9751791817675914, 0.769228162630255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1215 entries, 0 to 1214\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   time    1215 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 9.6 KB\n"
     ]
    }
   ],
   "source": [
    "#=================================================================#\n",
    "##### USER-DEFINED FUNCTIONS\n",
    "#def f_get_Normalization(X, norm_mode):\n",
    "    num_Patient, num_Feature = np.shape(X)\n",
    "\n",
    "    if norm_mode == 'standard': #zero mean unit variance\n",
    "        for j in range(num_Feature):\n",
    "            if np.std(X[:,j]) != 0:\n",
    "                X[:,j] = (X[:,j] - np.mean(X[:, j]))/np.std(X[:,j])\n",
    "            else:\n",
    "                X[:,j] = (X[:,j] - np.mean(X[:, j]))\n",
    "    elif norm_mode == 'normal': #min-max normalization\n",
    "        for j in range(num_Feature):\n",
    "            X[:,j] = (X[:,j] - np.min(X[:,j]))/(np.max(X[:,j]) - np.min(X[:,j]))\n",
    "    else:\n",
    "        print(\"INPUT MODE ERROR!\")\n",
    "\n",
    "    return X\n",
    "#=================================================================#\n",
    "\n",
    "\n",
    "\n",
    "##### DATASET SELECTION\n",
    "SEED    = 1111\n",
    "data_mode = 'metabric'  #{'metabric', 'support'}\n",
    "mode = 'meine'\n",
    "        \n",
    "if data_mode == 'metabric':\n",
    "    if mode == 'meine':\n",
    "        #X       = pd.read_csv('/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/meine/newdata_x_bad.csv')\n",
    "        tmp     = pd.read_csv('/Users/svpovol/Desktop/Bachelorarbeit/main_ordner/Data/meine/newdata_bad.csv')\n",
    "        T       = tmp[['time']]\n",
    "        Y       = tmp[['label']]\n",
    "        to_remove = ['t.act.12m', 'hpi.st.d.t.o'] #strong correlated features\n",
    "        #X = X.drop(to_remove, axis = 1)           #remove it\n",
    "        #f_get_Normalization:\n",
    "        #cols = X.columns.tolist()\n",
    "        #data            = f_get_Normalization(np.asarray(X[cols]), 'standard') \n",
    "        #X = pd.DataFrame(data,columns= cols)\n",
    "    else:\n",
    "        X       = pd.read_csv('./sample data/metabric_cleaned_features_final.csv')\n",
    "        tmp     = pd.read_csv('./sample data/metabric_label.csv')\n",
    "        T       = tmp[['event_time']]\n",
    "        Y       = tmp[['label']]\n",
    "    #time_interval_ = 10.\n",
    "    SEED    = 4321\n",
    "    if X.shape[0]>1215000:     #same size as my dataset\n",
    "        print(X.shape)\n",
    "        X= X.iloc[0:1215,:]\n",
    "        T= T.iloc[0:1215,:]\n",
    "        Y= Y.iloc[0:1215,:] \n",
    "\n",
    "tmp_folder = './results/' + data_mode + ' (seed ' + str(SEED) +')/'\n",
    "if not os.path.exists(tmp_folder):\n",
    "    os.makedirs(tmp_folder)\n",
    "\n",
    "# eval_time_horizons can be selected based on one's interest.\n",
    "eval_time_horizons = [int(T[Y.iloc[:,0] == 1].quantile(0.25)), int(T[Y.iloc[:,0] == 1].quantile(0.50)), int(T[Y.iloc[:,0] == 1].quantile(0.75))]\n",
    "\n",
    "\n",
    "tr_X,te_X, tr_T,te_T, tr_Y,te_Y = train_test_split(X, T, Y, test_size=0.2, random_state=1234)\n",
    "#eval_time_horizons =[11, 19, 30,48]#= [24, 48, 72]\n",
    "#T.shape,X.columns,X\n",
    "\n",
    "T.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = model_sq._get_ensemble_prediction(model_sq.underlying_models, model_sq.quilting_patterns, te_X, model_sq.all_time_horizons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23999999760000004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_all[3,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all[:, np.where(np.asarray(model_sq.all_time_horizons) <= eval_time)[0][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.asarray(model_sq.all_time_horizons) <= 21)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sq.all_time_horizons[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 \n",
      "\n",
      "[[0.00000000e+00 7.18460499e-06 1.80527725e-05 2.52893440e-05]\n",
      " [0.00000000e+00 1.68333595e-03 4.22435543e-03 5.91271725e-03]]\n",
      "0 1 \n",
      "\n",
      "[[0.00000000e+00 1.22914465e-05 3.60378476e-05 5.53487808e-05\n",
      "  9.36985891e-05 1.79491524e-04 2.19761956e-04 2.68804347e-04\n",
      "  3.15096157e-04 4.33654231e-04 4.95721520e-04]\n",
      " [0.00000000e+00 2.85435196e-03 8.34563077e-03 1.27888034e-02\n",
      "  2.15533062e-02 4.08783064e-02 4.98164805e-02 6.05885858e-02\n",
      "  7.06438291e-02 9.59054403e-02 1.08853676e-01]] \n",
      "\n",
      "0 2 \n",
      "\n",
      "[[0.00000000e+00 2.01344499e-04 5.10183640e-04 9.97220084e-04\n",
      "  1.30502432e-03 1.55809651e-03 2.03404313e-03 2.94159551e-03\n",
      "  3.86577114e-03 4.47703476e-03 7.23095854e-03 1.17949418e-02]\n",
      " [0.00000000e+00 3.93317036e-02 9.61739044e-02 1.77868714e-01\n",
      "  2.24896868e-01 2.61102260e-01 3.23642638e-01 4.25184603e-01\n",
      "  5.08600741e-01 5.54622710e-01 6.96552172e-01 7.98902952e-01]] \n",
      "\n",
      "0 3 \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "0 4 \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "0 5 \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "1 0 \n",
      "\n",
      "[[0.00000000e+00 1.97032006e-07 8.09896191e-07 2.33582796e-06]\n",
      " [0.00000000e+00 1.64352518e-05 6.75533676e-05 1.94806700e-04]]\n",
      "1 1 \n",
      "\n",
      "[[0.00000000e+00 6.29101660e-06 1.74500406e-05 3.60292077e-05\n",
      "  6.54312983e-05 1.10064923e-04 1.75508689e-04 2.68683536e-04\n",
      "  3.98032291e-04 5.73705242e-04 8.07750242e-04]\n",
      " [0.00000000e+00 5.24012024e-04 1.45217189e-03 2.99373300e-03\n",
      "  5.42370890e-03 9.09022026e-03 1.44181645e-02 2.19067950e-02\n",
      "  3.21182690e-02 4.56540705e-02 6.31168206e-02]] \n",
      "\n",
      "1 2 \n",
      "\n",
      "[[0.00000000e+00 3.95486844e-04 8.98800298e-04 1.53149263e-03\n",
      "  2.31794620e-03 3.28552968e-03 4.46473131e-03 5.88926127e-03\n",
      "  7.59611445e-03 9.62558350e-03 1.20212109e-02 1.48296682e-02]\n",
      " [0.00000000e+00 2.68488847e-02 5.88478771e-02 9.59816990e-02\n",
      "  1.37933273e-01 1.84072968e-01 2.33490716e-01 2.85069597e-01\n",
      "  3.37588887e-01 3.89837058e-01 4.40713858e-01 4.89305421e-01]] \n",
      "\n",
      "1 3 \n",
      "\n",
      "[[0.         0.00378551 0.00814007 0.01311975 0.01878159 0.02518284\n",
      "  0.03237997 0.04042759 0.04937724 0.0592761  0.07016557]\n",
      " [0.         0.04219493 0.08072863 0.11554548 0.14672954 0.17446351\n",
      "  0.1989926  0.2205953  0.23956132 0.25617615 0.27071096]] \n",
      "\n",
      "1 4 \n",
      "\n",
      "[[0.         0.01296477 0.0269957  0.04209728 0.05826186 0.07546877\n",
      "  0.09368394 0.11285973 0.13293522 0.1538369  0.17547973 0.19776855]\n",
      " [0.         0.01110465 0.02081221 0.02930347 0.0367373  0.04325254\n",
      "  0.04897    0.05399445 0.0584166  0.06231484 0.06575691 0.06880131]] \n",
      "\n",
      "1 5 \n",
      "\n",
      "[[0.         0.02326401 0.04684667 0.070632   0.09450431 0.11835035\n",
      "  0.1420612  0.16553407 0.18867369 0.21139343 0.23361612]\n",
      " [0.         0.00239381 0.00452194 0.00641712 0.00810769 0.00961827\n",
      "  0.01097026 0.01218226 0.01327051 0.01424917 0.01513064]]\n",
      "2 0 \n",
      "\n",
      "[[0.00000000e+00 1.91657250e-06 4.98191086e-06 7.20160237e-06]\n",
      " [0.00000000e+00 6.90210580e-04 1.79313563e-03 2.59103429e-03]]\n",
      "2 1 \n",
      "\n",
      "[[0.00000000e+00 4.35090632e-06 1.33189477e-05 2.12769987e-05\n",
      "  3.76717562e-05 7.74613333e-05 9.77946025e-05 1.24419152e-04\n",
      "  1.50262366e-04 2.21962991e-04 2.63627959e-04]\n",
      " [0.00000000e+00 1.56026160e-03 4.76856914e-03 7.60690710e-03\n",
      "  1.34287741e-02 2.74164237e-02 3.44875315e-02 4.36687045e-02\n",
      "  5.24968020e-02 7.65648147e-02 9.02683065e-02]] \n",
      "\n",
      "2 2 \n",
      "\n",
      "[[0.00000000e+00 1.52439459e-04 3.99646964e-04 8.07243806e-04\n",
      "  1.07116269e-03 1.30330320e-03 1.74591505e-03 2.62326796e-03\n",
      "  3.60443673e-03 4.28247084e-03 7.39635570e-03 9.99617792e-01]\n",
      " [0.00000000e+00 4.65970373e-02 1.16937412e-01 2.20088900e-01\n",
      "  2.79248291e-01 3.26836393e-01 4.07254284e-01 5.33322383e-01\n",
      "  6.34282069e-01 6.85862459e-01 8.11351117e-01 8.71298168e-01]] \n",
      "\n",
      "2 3 \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "2 4 \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "2 5 \n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "W_ =model_sq.quilting_patterns\n",
    "var = model_sq.all_time_horizons # model_sq.time_horizons\n",
    "for m in range(model_sq.M):\n",
    "            tmp_pred_ = model_sq.underlying_models[m].predict(te_X, var)\n",
    "\n",
    "            if m == 0:\n",
    "                pred_ = np.zeros(np.shape(tmp_pred_))\n",
    "            #else:\n",
    "            for tt in range(model_sq.K):\n",
    "                print(m,tt,'\\n')\n",
    "                if tt == 0:\n",
    "                    tmp_time_idx1 = np.asarray(var) <= model_sq.time_horizons[tt]\n",
    "                    #print(tmp_time_idx1)\n",
    "                    \n",
    "                    #print(tmp_time_idx1,'\\n',tmp_pred_[:2, tmp_time_idx1],'\\n',tmp_pred_[:2, tmp_time_idx1][:,[0]],'\\n',np.ones([1,np.sum(tmp_time_idx1)]))\n",
    "                    \n",
    "                    tmp_time_idx2 = np.asarray(var) > model_sq.time_horizons[tt]\n",
    "                    #print(tmp_time_idx2)\n",
    "                    #print(tmp_time_idx2,'\\n',tmp_pred_[:2, tmp_time_idx2])\n",
    "\n",
    "                    increment = tmp_pred_[:, tmp_time_idx1] - np.matmul(tmp_pred_[:, tmp_time_idx1][:,[0]], np.ones([1,np.sum(tmp_time_idx1)]))\n",
    "                    print(increment[:2,:])\n",
    "\n",
    "                    pred_[:, tmp_time_idx1] =  pred_[:, tmp_time_idx1] + W_[tt,m] * increment\n",
    "                    pred_[:, tmp_time_idx2] =  pred_[:, tmp_time_idx2] + W_[tt,m] * np.matmul(increment[:,[-1]], np.ones([1,np.sum(tmp_time_idx2)]))\n",
    "                elif tt == (model_sq.K - 1): #the last index  \n",
    "                    tmp_time_idx1 = np.asarray(var) > model_sq.time_horizons[tt-1]\n",
    "\n",
    "                    increment = tmp_pred_[:, tmp_time_idx1] - np.matmul(tmp_pred_[:, tmp_time_idx1][:,[0]], np.ones([1,np.sum(tmp_time_idx1)]))\n",
    "                    print(increment[:2,:])\n",
    "\n",
    "                    pred_[:, tmp_time_idx1] =  pred_[:, tmp_time_idx1] + W_[tt,m] * increment\n",
    "\n",
    "                else:\n",
    "                    tmp_time_idx1 = (np.asarray(var) > model_sq.time_horizons[tt-1]) & (np.asarray(var) <= model_sq.time_horizons[tt])\n",
    "                    tmp_time_idx2 = np.asarray(var) > model_sq.time_horizons[tt]\n",
    "\n",
    "                    increment = tmp_pred_[:, tmp_time_idx1] - np.matmul(tmp_pred_[:, tmp_time_idx1][:,[0]], np.ones([1,np.sum(tmp_time_idx1)]))\n",
    "                    print(increment[:2,:],'\\n')\n",
    "\n",
    "                    pred_[:, tmp_time_idx1] =  pred_[:, tmp_time_idx1] + W_[tt,m] * increment\n",
    "                    pred_[:, tmp_time_idx2] =  pred_[:, tmp_time_idx2] + W_[tt,m] * np.matmul(increment[:,[-1]], np.ones([1,np.sum(tmp_time_idx2)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
